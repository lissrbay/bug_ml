{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmVXQnhzpiOz",
    "outputId": "a29d3200-badb-4698-c205-940e17bae909"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import FloatTensor, LongTensor\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "#from google.colab import drive\n",
    "\n",
    "#drive.mount('/content/gdrive')\n",
    "#%cd gdrive/'My Drive'/ml/code2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "S93DGpt-ZJMc"
   },
   "outputs": [],
   "source": [
    "X = np.load('X(code2seq).npy')\n",
    "y = np.load('y(code2seq).npy')\n",
    "X_ = np.load('X(code2seq)2.npy')\n",
    "y_ = np.load('y(code2seq)2.npy')\n",
    "X = np.concatenate((X, X_), axis = 0)\n",
    "y = np.concatenate((y, y_), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6l96sl1v-9MV"
   },
   "outputs": [],
   "source": [
    "for n in range(X.shape[0]):\n",
    "    for i in range(X.shape[1]):\n",
    "        if np.sum(X[n][i]) == X.shape[2]:\n",
    "            y[n][i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMPZa1Dv_OXb"
   },
   "outputs": [],
   "source": [
    "def baseline(labels):\n",
    "    count = 0\n",
    "    for label in labels:\n",
    "        if label[0] == 1:\n",
    "            count += 1\n",
    "    return count / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8x6dbkpw_2TG",
    "outputId": "25c7e36a-c883-4ed0-9add-a6f66c024839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GjMlwXZcQyXM"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = X[:int(0.8*X.shape[0])], y[:int(0.8*y.shape[0])]\n",
    "test_x, test_y = X[int(0.8*X.shape[0]):], y[int(0.8*y.shape[0]):]\n",
    "#lstm_model.fit(train_x, train_y, batch_size=1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wv5GqCEemSo8"
   },
   "outputs": [],
   "source": [
    "def iterate_batches(data, batch_size):\n",
    "    X, y = data\n",
    "    n_samples = len(X)\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_indices = indices[start:end]\n",
    "        X_batch = X[batch_indices]\n",
    "        y_batch = y[batch_indices]\n",
    "            \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhFfbx6nm6iG",
    "outputId": "609caa7f-fbd0-405d-e135-6f6bf19a1d06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 80, 320), (4, 80))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = next(iterate_batches((train_x, train_y), 4))\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ra3cqXvdnBth"
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, word_emb_dim=384, lstm_hidden_dim=32, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        self.word_emb_dim = word_emb_dim\n",
    "\n",
    "        self.word_emb = nn.Embedding(2, word_emb_dim)\n",
    "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim,\n",
    "                            num_layers=lstm_layers_count, bidirectional=True)\n",
    "        self.tagger = nn.Linear(2 *  lstm_hidden_dim, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self.word_emb(torch.LongTensor([[0]]))\n",
    "        inputs[np.where(~inputs.detach().numpy().any(axis=2))] = emb\n",
    "        emb = self.word_emb(torch.LongTensor([[1]]))\n",
    "        inputs[np.where(np.sum(inputs.detach().numpy(), axis=2)==self.word_emb_dim)] = emb\n",
    "\n",
    "        res, _ = self.lstm(inputs)\n",
    "        tag = self.tagger(res)\n",
    "        return F.softmax(tag, 1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHFZUa7gqS5I",
    "outputId": "03e504da-07cc-4105-97ed-ad30f9ba2add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 80, 320])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    word_emb_dim = 320,\n",
    "    lstm_hidden_dim=40\n",
    ")\n",
    "\n",
    "X_batch, y_batch = torch.FloatTensor(train_x[:4]), torch.LongTensor(train_y[:4])\n",
    "print(X_batch.shape)\n",
    "logits = model(X_batch)\n",
    "mask = (y_batch == 1)\n",
    "float(torch.sum((torch.argmax(logits, 2) == y_batch) * mask)) / float(torch.sum(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    c = 0\n",
    "    for n in range(y_pred.shape[0]):\n",
    "        pred = []\n",
    "        for i in range(y_pred.shape[1]):\n",
    "            if y_pred[n][i][0] > y_pred[n][i][1]:\n",
    "                pred.append(0)\n",
    "            else:\n",
    "                pred.append(y_pred[n][i][1])\n",
    "        if (np.argmax(pred) == np.argmax(y_true[n])):\n",
    "            c += 1\n",
    "    return c/y_true.shape[0]\n",
    "accuracy(y_batch, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RunyQfoVcDgc",
    "outputId": "541cf635-1eba-4b4c-bd5a-7a9d6a9b3c59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6932, grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=2)\n",
    "criterion(logits.transpose(2, 1), y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "d0zj8viIqcMO"
   },
   "outputs": [],
   "source": [
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
    "                X_batch, y_batch = FloatTensor(X_batch), LongTensor(y_batch)\n",
    "                logits = model(X_batch)\n",
    "\n",
    "                loss = criterion(logits.transpose(2, 1), y_batch)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                correct_count += accuracy(y_batch, logits) * batch_size\n",
    "                sum_count += batch_size\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                    name, loss.item(), correct_count / sum_count)\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
    "            )\n",
    "\n",
    "    return epoch_loss / batches_count, correct_count / sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
    "        val_data=None, val_batch_size=None):\n",
    "        \n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "    all_train_acc = []\n",
    "    all_val_acc = []\n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_data is None:\n",
    "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')\n",
    "        all_train_acc.append(train_acc)\n",
    "        all_val_acc.append(val_acc)\n",
    "    return np.array(all_train_acc).max(), np.array(all_val_acc).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Qc13Av0dq7R",
    "outputId": "f85a5bf7-840b-4212-dc3f-d0aeb6580137"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 10] Train: Loss = 0.69031, Accuracy = 32.68%: 100%|██████████| 824/824 [00:28<00:00, 28.92it/s]\n",
      "[1 / 10]   Val: Loss = 0.69057, Accuracy = 30.70%: 100%|██████████| 206/206 [00:03<00:00, 62.74it/s]\n",
      "[2 / 10] Train: Loss = 0.69026, Accuracy = 34.01%: 100%|██████████| 824/824 [00:31<00:00, 25.84it/s]\n",
      "[2 / 10]   Val: Loss = 0.69073, Accuracy = 29.13%: 100%|██████████| 206/206 [00:03<00:00, 62.70it/s]\n",
      "[3 / 10] Train: Loss = 0.69047, Accuracy = 31.52%: 100%|██████████| 824/824 [00:33<00:00, 24.47it/s]\n",
      "[3 / 10]   Val: Loss = 0.69069, Accuracy = 29.85%: 100%|██████████| 206/206 [00:04<00:00, 47.36it/s]\n",
      "[4 / 10] Train: Loss = 0.69034, Accuracy = 33.89%: 100%|██████████| 824/824 [00:37<00:00, 22.16it/s]\n",
      "[4 / 10]   Val: Loss = 0.69051, Accuracy = 32.04%: 100%|██████████| 206/206 [00:04<00:00, 49.54it/s]\n",
      "[5 / 10] Train: Loss = 0.69025, Accuracy = 36.07%: 100%|██████████| 824/824 [01:06<00:00, 12.45it/s]\n",
      "[5 / 10]   Val: Loss = 0.69089, Accuracy = 34.59%: 100%|██████████| 206/206 [00:03<00:00, 51.80it/s]\n",
      "[6 / 10] Train: Loss = 0.69032, Accuracy = 36.23%: 100%|██████████| 824/824 [00:35<00:00, 23.28it/s]\n",
      "[6 / 10]   Val: Loss = 0.69015, Accuracy = 38.11%: 100%|██████████| 206/206 [00:03<00:00, 56.90it/s]\n",
      "[7 / 10] Train: Loss = 0.69002, Accuracy = 37.59%: 100%|██████████| 824/824 [00:30<00:00, 27.19it/s]\n",
      "[7 / 10]   Val: Loss = 0.69051, Accuracy = 31.43%: 100%|██████████| 206/206 [00:03<00:00, 65.11it/s]\n",
      "[8 / 10] Train: Loss = 0.69016, Accuracy = 36.50%: 100%|██████████| 824/824 [00:32<00:00, 25.08it/s]\n",
      "[8 / 10]   Val: Loss = 0.69043, Accuracy = 34.83%: 100%|██████████| 206/206 [00:03<00:00, 54.89it/s]\n",
      "[9 / 10] Train: Loss = 0.69032, Accuracy = 35.53%: 100%|██████████| 824/824 [00:30<00:00, 27.37it/s]\n",
      "[9 / 10]   Val: Loss = 0.69040, Accuracy = 33.74%: 100%|██████████| 206/206 [00:03<00:00, 55.63it/s]\n",
      "[10 / 10] Train: Loss = 0.69022, Accuracy = 35.47%: 100%|██████████| 824/824 [00:31<00:00, 26.26it/s]\n",
      "[10 / 10]   Val: Loss = 0.69068, Accuracy = 33.37%: 100%|██████████| 206/206 [00:03<00:00, 55.52it/s]\n",
      "[1 / 15] Train: Loss = 0.69006, Accuracy = 37.83%: 100%|██████████| 824/824 [00:32<00:00, 25.44it/s]\n",
      "[1 / 15]   Val: Loss = 0.69035, Accuracy = 34.95%: 100%|██████████| 206/206 [00:03<00:00, 52.34it/s]\n",
      "[2 / 15] Train: Loss = 0.69008, Accuracy = 37.68%: 100%|██████████| 824/824 [00:32<00:00, 25.52it/s]\n",
      "[2 / 15]   Val: Loss = 0.69022, Accuracy = 37.50%: 100%|██████████| 206/206 [00:04<00:00, 50.36it/s]\n",
      "[3 / 15] Train: Loss = 0.69038, Accuracy = 36.80%: 100%|██████████| 824/824 [00:33<00:00, 24.29it/s]\n",
      "[3 / 15]   Val: Loss = 0.69066, Accuracy = 32.16%: 100%|██████████| 206/206 [00:03<00:00, 57.78it/s]\n",
      "[4 / 15] Train: Loss = 0.69022, Accuracy = 35.47%: 100%|██████████| 824/824 [00:32<00:00, 25.69it/s]\n",
      "[4 / 15]   Val: Loss = 0.69025, Accuracy = 35.68%: 100%|██████████| 206/206 [00:03<00:00, 58.45it/s]\n",
      "[5 / 15] Train: Loss = 0.68999, Accuracy = 37.47%: 100%|██████████| 824/824 [00:28<00:00, 28.55it/s]\n",
      "[5 / 15]   Val: Loss = 0.69061, Accuracy = 32.89%: 100%|██████████| 206/206 [00:03<00:00, 56.13it/s]\n",
      "[6 / 15] Train: Loss = 0.69039, Accuracy = 35.13%: 100%|██████████| 824/824 [00:27<00:00, 29.94it/s]\n",
      "[6 / 15]   Val: Loss = 0.69045, Accuracy = 35.19%: 100%|██████████| 206/206 [00:03<00:00, 55.87it/s]\n",
      "[7 / 15] Train: Loss = 0.69020, Accuracy = 37.86%: 100%|██████████| 824/824 [00:32<00:00, 25.53it/s]\n",
      "[7 / 15]   Val: Loss = 0.69045, Accuracy = 34.71%: 100%|██████████| 206/206 [00:03<00:00, 59.01it/s]\n",
      "[8 / 15] Train: Loss = 0.69031, Accuracy = 35.32%: 100%|██████████| 824/824 [00:35<00:00, 23.34it/s]\n",
      "[8 / 15]   Val: Loss = 0.69063, Accuracy = 33.98%: 100%|██████████| 206/206 [00:04<00:00, 48.44it/s]\n",
      "[9 / 15] Train: Loss = 0.69019, Accuracy = 35.80%: 100%|██████████| 824/824 [00:34<00:00, 24.07it/s]\n",
      "[9 / 15]   Val: Loss = 0.69031, Accuracy = 35.19%: 100%|██████████| 206/206 [00:04<00:00, 48.69it/s]\n",
      "[10 / 15] Train: Loss = 0.69016, Accuracy = 35.47%: 100%|██████████| 824/824 [00:34<00:00, 23.62it/s]\n",
      "[10 / 15]   Val: Loss = 0.69044, Accuracy = 35.19%: 100%|██████████| 206/206 [00:04<00:00, 49.89it/s]\n",
      "[11 / 15] Train: Loss = 0.69018, Accuracy = 35.22%: 100%|██████████| 824/824 [00:34<00:00, 23.92it/s]\n",
      "[11 / 15]   Val: Loss = 0.69035, Accuracy = 33.37%: 100%|██████████| 206/206 [00:04<00:00, 49.93it/s]\n",
      "[12 / 15] Train: Loss = 0.69004, Accuracy = 36.95%: 100%|██████████| 824/824 [00:33<00:00, 24.43it/s]\n",
      "[12 / 15]   Val: Loss = 0.69033, Accuracy = 33.98%: 100%|██████████| 206/206 [00:04<00:00, 50.59it/s]\n",
      "[13 / 15] Train: Loss = 0.69000, Accuracy = 36.98%: 100%|██████████| 824/824 [00:34<00:00, 24.07it/s]\n",
      "[13 / 15]   Val: Loss = 0.69025, Accuracy = 34.59%: 100%|██████████| 206/206 [00:04<00:00, 50.35it/s]\n",
      "[14 / 15] Train: Loss = 0.68999, Accuracy = 37.80%: 100%|██████████| 824/824 [00:34<00:00, 24.07it/s]\n",
      "[14 / 15]   Val: Loss = 0.69020, Accuracy = 35.32%: 100%|██████████| 206/206 [00:04<00:00, 49.42it/s]\n",
      "[15 / 15] Train: Loss = 0.69007, Accuracy = 36.41%: 100%|██████████| 824/824 [00:34<00:00, 23.82it/s]\n",
      "[15 / 15]   Val: Loss = 0.69012, Accuracy = 36.41%: 100%|██████████| 206/206 [00:04<00:00, 48.93it/s]\n",
      "[1 / 10] Train: Loss = 0.69003, Accuracy = 37.23%: 100%|██████████| 824/824 [00:35<00:00, 23.35it/s]\n",
      "[1 / 10]   Val: Loss = 0.69018, Accuracy = 36.17%: 100%|██████████| 206/206 [00:03<00:00, 52.56it/s]\n",
      "[2 / 10] Train: Loss = 0.68984, Accuracy = 39.02%: 100%|██████████| 824/824 [00:34<00:00, 23.92it/s]\n",
      "[2 / 10]   Val: Loss = 0.69022, Accuracy = 35.80%: 100%|██████████| 206/206 [00:03<00:00, 55.37it/s]\n",
      "[3 / 10] Train: Loss = 0.68992, Accuracy = 37.89%: 100%|██████████| 824/824 [00:33<00:00, 24.29it/s]\n",
      "[3 / 10]   Val: Loss = 0.69001, Accuracy = 37.62%: 100%|██████████| 206/206 [00:03<00:00, 53.37it/s]\n",
      "[4 / 10] Train: Loss = 0.68982, Accuracy = 38.77%: 100%|██████████| 824/824 [00:33<00:00, 24.74it/s]\n",
      "[4 / 10]   Val: Loss = 0.69022, Accuracy = 36.29%: 100%|██████████| 206/206 [00:04<00:00, 48.69it/s]\n",
      "[5 / 10] Train: Loss = 0.68981, Accuracy = 39.23%: 100%|██████████| 824/824 [00:38<00:00, 21.59it/s]\n",
      "[5 / 10]   Val: Loss = 0.69026, Accuracy = 34.83%: 100%|██████████| 206/206 [00:04<00:00, 47.68it/s]\n",
      "[6 / 10] Train: Loss = 0.68984, Accuracy = 39.14%: 100%|██████████| 824/824 [00:39<00:00, 20.61it/s]\n",
      "[6 / 10]   Val: Loss = 0.69013, Accuracy = 36.17%: 100%|██████████| 206/206 [00:04<00:00, 47.66it/s]\n",
      "[7 / 10] Train: Loss = 0.68978, Accuracy = 39.38%: 100%|██████████| 824/824 [00:39<00:00, 20.63it/s]\n",
      "[7 / 10]   Val: Loss = 0.69002, Accuracy = 37.01%: 100%|██████████| 206/206 [00:03<00:00, 51.64it/s]\n",
      "[8 / 10] Train: Loss = 0.68974, Accuracy = 39.62%: 100%|██████████| 824/824 [00:29<00:00, 27.64it/s]\n",
      "[8 / 10]   Val: Loss = 0.69023, Accuracy = 37.01%: 100%|██████████| 206/206 [00:02<00:00, 77.60it/s]\n",
      "[9 / 10] Train: Loss = 0.68966, Accuracy = 40.59%: 100%|██████████| 824/824 [00:24<00:00, 33.46it/s]\n",
      "[9 / 10]   Val: Loss = 0.68999, Accuracy = 37.50%: 100%|██████████| 206/206 [00:03<00:00, 66.43it/s]\n",
      "[10 / 10] Train: Loss = 0.68972, Accuracy = 39.59%: 100%|██████████| 824/824 [00:25<00:00, 32.56it/s]\n",
      "[10 / 10]   Val: Loss = 0.68996, Accuracy = 37.01%: 100%|██████████| 206/206 [00:02<00:00, 72.51it/s]\n",
      "[1 / 15] Train: Loss = 0.68965, Accuracy = 39.99%: 100%|██████████| 824/824 [00:26<00:00, 31.69it/s]\n",
      "[1 / 15]   Val: Loss = 0.69005, Accuracy = 37.38%: 100%|██████████| 206/206 [00:02<00:00, 75.12it/s]\n",
      "[2 / 15] Train: Loss = 0.68976, Accuracy = 38.53%: 100%|██████████| 824/824 [00:22<00:00, 36.33it/s]\n",
      "[2 / 15]   Val: Loss = 0.68990, Accuracy = 38.83%: 100%|██████████| 206/206 [00:02<00:00, 72.55it/s]\n",
      "[3 / 15] Train: Loss = 0.68979, Accuracy = 38.44%: 100%|██████████| 824/824 [00:26<00:00, 31.31it/s]\n",
      "[3 / 15]   Val: Loss = 0.69016, Accuracy = 36.53%: 100%|██████████| 206/206 [00:03<00:00, 66.54it/s]\n",
      "[4 / 15] Train: Loss = 0.68980, Accuracy = 38.29%: 100%|██████████| 824/824 [00:29<00:00, 28.35it/s]\n",
      "[4 / 15]   Val: Loss = 0.69003, Accuracy = 36.65%: 100%|██████████| 206/206 [00:04<00:00, 50.93it/s]\n",
      "[5 / 15] Train: Loss = 0.68966, Accuracy = 39.20%: 100%|██████████| 824/824 [00:41<00:00, 19.83it/s]\n",
      "[5 / 15]   Val: Loss = 0.68999, Accuracy = 35.32%: 100%|██████████| 206/206 [00:04<00:00, 41.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[6 / 15] Train: Loss = 0.68964, Accuracy = 39.99%: 100%|██████████| 824/824 [00:39<00:00, 20.98it/s]\n",
      "[6 / 15]   Val: Loss = 0.68986, Accuracy = 37.74%: 100%|██████████| 206/206 [00:04<00:00, 49.21it/s]\n",
      "[7 / 15] Train: Loss = 0.68593, Accuracy = 39.84%:  41%|████      | 337/824 [00:14<00:20, 23.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b5fae6434698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manneal_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manneal_coeff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             train_acc, val_acc = fit(model, criterion, optimizer, train_data=(train_x, train_y), epochs_count=epoch,\n\u001b[0;32m---> 24\u001b[0;31m                 batch_size=4, val_data=(test_x, test_y), val_batch_size=4)\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mrun_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3b8f5ab42153>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_data, epochs_count, batch_size, val_data, val_batch_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mname_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[{} / {}] '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3b8f5ab42153>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data, batch_size, optimizer, name)\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mcorrect_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0msum_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1845c7e0bd8b>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    word_emb_dim = 320,\n",
    "    lstm_hidden_dim=40\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=2).cuda()\n",
    "lrs = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "epochs = [10, 15]\n",
    "RunResult = namedtuple(\"RunResult\", ['model', 'train_history', 'val_history'])\n",
    "Parameters = namedtuple(\"Parameters\", ['lr', 'epoch', 'optim', 'anneal_coef', 'anneal_epoch'])\n",
    "anneal_coeff = 0.1\n",
    "anneal_epochs = [5, 10]\n",
    "optims = optim.Adam\n",
    "run_record = []\n",
    "train_parameters = []\n",
    "for anneal_epoch in anneal_epochs:\n",
    "    for lr in lrs:\n",
    "        for epoch in epochs:\n",
    "            train_parameters.append(Parameters(lr, epoch, optims, anneal_coeff, anneal_epoch))\n",
    "            loss = nn.CrossEntropyLoss().cuda()\n",
    "            #model.to('cuda')\n",
    "            optimizer = optims(model.parameters(), lr=lr)\n",
    "            scheduler = StepLR(optimizer, step_size = anneal_epoch, gamma = anneal_coeff)\n",
    "            train_acc, val_acc = fit(model, criterion, optimizer, train_data=(train_x, train_y), epochs_count=epoch,\n",
    "                batch_size=4, val_data=(test_x, test_y), val_batch_size=4)\n",
    "            run_record.append(RunResult(model, train_acc, val_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PdHlBwqF9RX3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results = []\n",
    "for record in run_record:\n",
    "    results.append({'train_acc':record.train_history, 'val_acc':record.val_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('results.txt', 'w')\n",
    "json.dump(results, f, indent=4)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitanaconda3virtualenvd0bde01ecd494ffd86cb8096d0024b2f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
